\section{Introduction}
The following report describes our implementation of a Spam Filter. The main aim of any Spam Filter is to distinguish emails into one of two classes - unwanted \emph{Spam} emails and wanted \emph{Ham} emails. The fight against spam has been on-going effort since the inception of Email technology and is still heavily researched in the field of machine learning to this day. Our Spam Filter is attempted in the form of a Naive Bayes classifier along with several pre-processing techniques to filter out noise and improve performance. Naive Bayes is a commonly used classification technique used for Spam Filtering, still in use till this day by popular email clients due to its simplicity and surprisingly good performance.

In this report we will be making use of a given labelled set of emails to perform training. 
This labelled set will also be used to evaluate the performance of our classifier using 10-fold cross validation. 
Each fold will be used to calculate most of the standard machine learning performance metrics such as accuracy, recall and precision and as a final measure we will be reporting performance metrics as the overall average between each of the 10 folds. 
The standard deviation is also derived from the results in order to provide a base for comparison between the different classifiers.
As with all standard binary classification processes, we shall be using the terms positive and negative within the report to distinguish between the two possible classes - \emph{Spam} as positive and \emph{Ham} as negative.

To optimise the classification performance, we attempt to improve the quality of input data using various pre-processing techniques to filter out noise, normalise features and minimise the overall dimensionality. Doing so is an important step into achieving best results without altering the actual classification process itself.

A focus on our Naive Bayes implementation using the Bag of Words model will be made throughout the report.
An emphasis on optimising the performance through the selection of correct parameters is also given throughout the various sections covered.
However we shall also take the time at the end of the report to compare the performance of our implementation with other third party machine learning models such as the Decision Tree.
\todo{a bit more here.. NOTE: If we stick to just Decision tree we need to change the grammar of the above paragraph a bit}

In addition to the quality of classification results, we will be taking a look at improving the runtime of the classification and training process.
With a longer runtime, one might be able to increase the quality of a classifier  significantly (e.g. doing an exhaustive search over all possible models) but the runtime required to do so could be infeasibly large. We therefore attempt to minimise the runtime of the training and classification process with little or (at best) no loss in classification quality.

All reported times are based on running our implementation on two core Intel i7-640L CPU with a frequency of 2.1GHz per core and 8Gb of main memory.

\todo{State best performance!}
