\section{Introduction}
The following report describes our implementation of a spam filter.
\todo{This filter classifies emails by their content if they are unwanted (spam) mails or wanted (ham) mails using various preprocessing techniques and a Naive Bayes classifier.}

As we were only given a labelled training set, we are evaluating the performance of our classifier using 10-fold cross validation.
For each fold we are calculating the accuracy and reporting as a final measure the overall averaged accuracy and the sample standard deviation to compare the different classifier instantiations.
As in a normal binary classification process, one always uses the terms positive and negative class, we are \todo{defining} \emph{spam} to be the positive class and \emph{ham} the negative class.

To optimise the classification performance, we pre-process the input data using various techniques to filter out noise, normalise the features and minimise the overall dimensionality.

As there is no one best classifier, we are comparing different classifiers for the given training set using different parameter instantiations.
\todo{a bit more here..}

In addition to the classification quality, we will do have a look at the runtime of the classification and training process too.
With a longer runtime, one might be able to increase the quality of the classifier (e.g. doing an exhaustive search over all possible modeles) significantly but the needed runtime could be infeasably large.
As a minor factor we are trying to minimise the runtime of the training and the test set with minimal or (at best) no loss in classification quality.
All reported times are based on a two core Intel i7-640L CPU with a frequency of 2.1GHz per core and 8Gb of main memory.

\todo{State best performance!}
