\section{Conclusion}

The Naive Bayes classifier proved to be a surprisingly efficient machine learning technique despite its aptly given name (It is sometimes even lovingly referred to as Idiots Bayes due to its simplicity \cite{idiotsbayes2001}).
It has proven to output results with high accuracy, precision and recall - even outperforming more advanced machine learning techniques such as Decision Trees.
With a final accuracy of 0.984 and precision of 96.8 calculated through cross validation, our email classifier should correctly distinguish between ham and spam emails on a number of different test sets.

Future work can be done to both improve pre-processing techniques by further analysing meta-data within the headers and including additional text processing techniques such as spell correction to conflate words further into their respective features. Further natural language processing techniques can also be attempted on the text and a comparison in performance to the Bernoulli model for Naive Bayes can also be attempted in future work.

